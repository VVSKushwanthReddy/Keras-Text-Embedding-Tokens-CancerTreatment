{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimentions :  (3321, 4)\n",
      "Feature names:  ['ID' 'Gene' 'Variation' 'Class']\n",
      "\n",
      "    ID    Gene             Variation  Class\n",
      "0   0  FAM58A  Truncating Mutations      1\n",
      "1   1     CBL                 W802*      2\n",
      "2   2     CBL                 Q249E      2\n",
      "3   3     CBL                 N454D      3\n",
      "4   4     CBL                 L399V      4\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('training_variants')\n",
    "print(\"Dimentions : \",data.shape)\n",
    "print(\"Feature names: \", data.columns.values)\n",
    "print(\"\\n\",data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimentions :  (3321, 2)\n",
      "Feature names:  ['ID' 'TEXT']\n",
      "\n",
      "    ID                                               TEXT\n",
      "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
      "1   1   Abstract Background  Non-small cell lung canc...\n",
      "2   2   Abstract Background  Non-small cell lung canc...\n",
      "3   3  Recent evidence has demonstrated that acquired...\n",
      "4   4  Oncogenic mutations in the monomeric Casitas B...\n"
     ]
    }
   ],
   "source": [
    "data_text = pd.read_csv('training_text', sep='\\|\\|', engine='python', names=['ID','TEXT'], skiprows=1)\n",
    "print(\"Dimentions : \",data_text.shape)\n",
    "print(\"Feature names: \", data_text.columns.values)\n",
    "print(\"\\n\",data_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def nlp_preprocessing(total_text, index, column):\n",
    "    if type(total_text) is not int:\n",
    "        string = ''\n",
    "        # replacing all special characters with space\n",
    "        total_text = re.sub('[^a-zA-Z0-9\\n]',' ',total_text)\n",
    "        #removing all numbers\n",
    "        total_text = re.sub(r'[0-9]+', '', total_text)\n",
    "        # removing all extra spaces\n",
    "        total_text = re.sub('\\s+',' ',total_text)\n",
    "        # converting all chars to lower\n",
    "        total_text = total_text.lower()\n",
    "        \n",
    "\n",
    "        for word in total_text.split():\n",
    "            #removing stop words\n",
    "            if not word in stop_words:\n",
    "                string += word+' '\n",
    "                \n",
    "        data_text[column][index] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no text for some Indexes:  1109\n",
      "There is no text for some Indexes:  1277\n",
      "There is no text for some Indexes:  1407\n",
      "There is no text for some Indexes:  1639\n",
      "There is no text for some Indexes:  2755\n"
     ]
    }
   ],
   "source": [
    "for index, row in data_text.iterrows():\n",
    "    if type(row['TEXT']) is str:\n",
    "        nlp_preprocessing(row[\"TEXT\"], index, column = 'TEXT')\n",
    "    else:\n",
    "        print(\"There is no text for some Indexes: \", index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin dependent kinases cdks regulate variety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrated acquired uniparen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic mutations monomeric casitas b lineag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                TEXT  \n",
       "0  cyclin dependent kinases cdks regulate variety...  \n",
       "1  abstract background non small cell lung cancer...  \n",
       "2  abstract background non small cell lung cancer...  \n",
       "3  recent evidence demonstrated acquired uniparen...  \n",
       "4  oncogenic mutations monomeric casitas b lineag...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data, data_text, on=\"ID\", how='left')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv (r'D:/Users/kpannegatla/Desktop/ML/Cancer/data.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109    NaN\n",
       "1277    NaN\n",
       "1407    NaN\n",
       "1639    NaN\n",
       "2755    NaN\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['TEXT'].isnull(),'TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'].fillna(data['Gene']+' '+data['Variation'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin dependent kinases cdks regulate variety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrated acquired uniparen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic mutations monomeric casitas b lineag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                TEXT  \n",
       "0  cyclin dependent kinases cdks regulate variety...  \n",
       "1  abstract background non small cell lung cancer...  \n",
       "2  abstract background non small cell lung cancer...  \n",
       "3  recent evidence demonstrated acquired uniparen...  \n",
       "4  oncogenic mutations monomeric casitas b lineag...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "tokens = [word_tokenize(sen) for sen in data.TEXT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin dependent kinases cdks regulate variety...</td>\n",
       "      <td>[cyclin, dependent, kinases, cdks, regulate, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "      <td>[abstract, background, non, small, cell, lung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "      <td>[abstract, background, non, small, cell, lung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrated acquired uniparen...</td>\n",
       "      <td>[recent, evidence, demonstrated, acquired, uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic mutations monomeric casitas b lineag...</td>\n",
       "      <td>[oncogenic, mutations, monomeric, casitas, b, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  cyclin dependent kinases cdks regulate variety...   \n",
       "1  abstract background non small cell lung cancer...   \n",
       "2  abstract background non small cell lung cancer...   \n",
       "3  recent evidence demonstrated acquired uniparen...   \n",
       "4  oncogenic mutations monomeric casitas b lineag...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [cyclin, dependent, kinases, cdks, regulate, v...  \n",
       "1  [abstract, background, non, small, cell, lung,...  \n",
       "2  [abstract, background, non, small, cell, lung,...  \n",
       "3  [recent, evidence, demonstrated, acquired, uni...  \n",
       "4  [oncogenic, mutations, monomeric, casitas, b, ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting total words and length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, \n",
    "                                         test_size=0.20, \n",
    "                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16106085 words total, with a vocabulary size of 85159\n",
      "Max sentence length is 50880\n"
     ]
    }
   ],
   "source": [
    "all_training_words = [word for tokens in data_train[\"tokens\"] for word in tokens]\n",
    "training_sentence_lengths = [len(tokens) for tokens in data_train[\"tokens\"]]\n",
    "TRAINING_VOCAB = sorted(list(set(all_training_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(TRAINING_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(training_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6064.038027108434"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean(training_sentence_lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4254511 words total, with a vocabulary size of 48102\n",
      "Max sentence length is 31714\n"
     ]
    }
   ],
   "source": [
    "all_test_words = [word for tokens in data_test['tokens'] for word in tokens]\n",
    "test_sentence_lengths = [len(tokens) for tokens in data_test['tokens']]\n",
    "TEST_VOCAB = sorted(list(set(all_test_words)))\n",
    "print('%s words total, with a vocabulary size of %s' % (len(all_test_words), len(TEST_VOCAB)))\n",
    "print('Max sentence length is %s' % max(test_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6397.760902255639"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean(test_sentence_lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>2241</td>\n",
       "      <td>PTEN</td>\n",
       "      <td>D331G</td>\n",
       "      <td>4</td>\n",
       "      <td>tumor suppressor gene pten frequently mutated ...</td>\n",
       "      <td>[tumor, suppressor, gene, pten, frequently, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1459</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>V755I</td>\n",
       "      <td>5</td>\n",
       "      <td>discovery oncogenic driver mutations subsequen...</td>\n",
       "      <td>[discovery, oncogenic, driver, mutations, subs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>468</td>\n",
       "      <td>TP53</td>\n",
       "      <td>K291Q</td>\n",
       "      <td>1</td>\n",
       "      <td>tumor suppressor p dependent apoptosis thought...</td>\n",
       "      <td>[tumor, suppressor, p, dependent, apoptosis, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>3271</td>\n",
       "      <td>RET</td>\n",
       "      <td>L790F</td>\n",
       "      <td>7</td>\n",
       "      <td>mutations ret receptor tyrosine kinase associa...</td>\n",
       "      <td>[mutations, ret, receptor, tyrosine, kinase, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1580</td>\n",
       "      <td>MPL</td>\n",
       "      <td>W515K</td>\n",
       "      <td>2</td>\n",
       "      <td>recently gain function mpl mutation mplwl desc...</td>\n",
       "      <td>[recently, gain, function, mpl, mutation, mplw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID   Gene Variation  Class  \\\n",
       "2241  2241   PTEN     D331G      4   \n",
       "1459  1459  FGFR2     V755I      5   \n",
       "468    468   TP53     K291Q      1   \n",
       "3271  3271    RET     L790F      7   \n",
       "1580  1580    MPL     W515K      2   \n",
       "\n",
       "                                                   TEXT  \\\n",
       "2241  tumor suppressor gene pten frequently mutated ...   \n",
       "1459  discovery oncogenic driver mutations subsequen...   \n",
       "468   tumor suppressor p dependent apoptosis thought...   \n",
       "3271  mutations ret receptor tyrosine kinase associa...   \n",
       "1580  recently gain function mpl mutation mplwl desc...   \n",
       "\n",
       "                                                 tokens  \n",
       "2241  [tumor, suppressor, gene, pten, frequently, mu...  \n",
       "1459  [discovery, oncogenic, driver, mutations, subs...  \n",
       "468   [tumor, suppressor, p, dependent, apoptosis, t...  \n",
       "3271  [mutations, ret, receptor, tyrosine, kinase, a...  \n",
       "1580  [recently, gain, function, mpl, mutation, mplw...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['ID','Class','tokens'], axis=1)\n",
    "\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing data for TEXT feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = list(X_train[\"TEXT\"])\n",
    "X1_test = list(X_test[\"TEXT\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "#MAX_NB_WORDS = 100000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB))\n",
    "tokenizer.fit_on_texts(X1_train)\n",
    "\n",
    "X1_train = tokenizer.texts_to_sequences(X1_train)\n",
    "X1_test = tokenizer.texts_to_sequences(X1_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "X1_train = pad_sequences(X1_train, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X1_test = pad_sequences(X1_test, padding='post', maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for Gene and Variation feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train  = X_train[['Gene','Variation']]\n",
    "\n",
    "X2_test  = X_test[['Gene','Variation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = pd.get_dummies(X2_train, columns=['Gene','Variation'], drop_first=True)\n",
    "\n",
    "X2_test = pd.get_dummies(X2_test, columns=['Gene','Variation'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 2646)\n",
      "(665, 769)\n"
     ]
    }
   ],
   "source": [
    "print(X2_train.shape)\n",
    "#print(X1_train.shape)\n",
    "print(X2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating NN\n",
    "Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "size = X2_train.shape[1]\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submodel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, EMBEDDING_DIM)(input_1)\n",
    "LSTM_Layer_1 = LSTM(64)(embedding_layer)\n",
    "Dropout_1 = Dropout(0.3)(LSTM_Layer_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submodel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = Input(shape=(size,)) \n",
    "\n",
    "dense_layer_1 = Dense(32, activation='relu')(input_2)\n",
    "Dropout_2 = Dropout(0.3)(dense_layer_1)\n",
    "dense_layer_2 = Dense(32, activation='relu')(Dropout_2)\n",
    "Dropout_3 = Dropout(0.3)(dense_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_layer = Concatenate()([Dropout_1, Dropout_3])\n",
    "dense_layer_3 = Dense(32, activation='relu')(concat_layer)\n",
    "output = Dense(10, activation='softmax')(dense_layer_3)\n",
    "model = Model(inputs=[input_1, input_2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 2646)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           84704       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 2000, 100)    8515400     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 64)           42240       embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           1056        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96)           0           dropout_14[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           3104        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           330         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,646,834\n",
      "Trainable params: 8,646,834\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in d:\\users\\kpannegatla\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in d:\\users\\kpannegatla\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.utils import plot_model\\nplot_model(model, to_file='model_plot3.png', show_shapes=True, show_layer_names=True)\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot3.png', show_shapes=True, show_layer_names=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2124 samples, validate on 532 samples\n",
      "Epoch 1/10\n",
      "2124/2124 [==============================] - 584s 275ms/step - loss: 2.2525 - acc: 0.2524 - val_loss: 2.0461 - val_acc: 0.3083\n",
      "Epoch 2/10\n",
      "2124/2124 [==============================] - 1075s 506ms/step - loss: 1.9027 - acc: 0.2764 - val_loss: 1.8635 - val_acc: 0.3383\n",
      "Epoch 3/10\n",
      "2124/2124 [==============================] - 549s 258ms/step - loss: 1.8285 - acc: 0.2924 - val_loss: 1.8094 - val_acc: 0.3553\n",
      "Epoch 4/10\n",
      "2124/2124 [==============================] - 2023s 953ms/step - loss: 1.7216 - acc: 0.3649 - val_loss: 1.6496 - val_acc: 0.4248\n",
      "Epoch 5/10\n",
      "2124/2124 [==============================] - 596s 281ms/step - loss: 1.4847 - acc: 0.4750 - val_loss: 1.4708 - val_acc: 0.4850\n",
      "Epoch 6/10\n",
      "2124/2124 [==============================] - 895s 421ms/step - loss: 1.2367 - acc: 0.5612 - val_loss: 1.3573 - val_acc: 0.5263\n",
      "Epoch 7/10\n",
      " 896/2124 [===========>..................] - ETA: 5:38 - loss: 1.0183 - acc: 0.6708"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node gradients/lstm_14/TensorArrayV2Stack/TensorListStack_grad/TensorListFromTensor (defined at D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_6196]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-bf7a7f5bdb82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node gradients/lstm_14/TensorArrayV2Stack/TensorListStack_grad/TensorListFromTensor (defined at D:\\Users\\kpannegatla\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_6196]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X1_train, X2_train], y=y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
